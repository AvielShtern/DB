{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d56979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col,isnan, when, count\n",
    "import os\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "PATH_TO_WORK_DIR = \"/Users/avielshtern/Desktop/semester_b/DATABASE/EX/db_ex/ex2\"\n",
    "CSV_SUFFIX = \".csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d948a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/avielshtern/anaconda3/envs/db/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/03/31 17:17:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "paths_to_csv_files = [os.path.join(PATH_TO_WORK_DIR, file_name) for file_name in os.listdir(PATH_TO_WORK_DIR) if file_name.endswith(CSV_SUFFIX)]\n",
    "data_frames = [spark.read.csv(path,header=True,inferSchema=True) for path in paths_to_csv_files]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country-info\n",
      "+------------+\n",
      "|countryabbrv|\n",
      "+------------+\n",
      "|eg          |\n",
      "|il          |\n",
      "|cl          |\n",
      "|ro          |\n",
      "|jp          |\n",
      "|pl          |\n",
      "|cn          |\n",
      "|za          |\n",
      "|bd          |\n",
      "|ir          |\n",
      "|pt          |\n",
      "|in          |\n",
      "|au          |\n",
      "|pk          |\n",
      "|sg          |\n",
      "|uk          |\n",
      "|ae          |\n",
      "|hk          |\n",
      "|be          |\n",
      "|qa          |\n",
      "|tw          |\n",
      "|sa          |\n",
      "|co          |\n",
      "|tr          |\n",
      "|de          |\n",
      "|lu          |\n",
      "|br          |\n",
      "|jo          |\n",
      "|es          |\n",
      "|kr          |\n",
      "|it          |\n",
      "|ar          |\n",
      "|ph          |\n",
      "|nl          |\n",
      "|hu          |\n",
      "|ca          |\n",
      "|my          |\n",
      "|nz          |\n",
      "|ee          |\n",
      "|gr          |\n",
      "|ru          |\n",
      "|mt          |\n",
      "|th          |\n",
      "|ch          |\n",
      "|no          |\n",
      "|cy          |\n",
      "|at          |\n",
      "|cz          |\n",
      "|fr          |\n",
      "|se          |\n",
      "|ie          |\n",
      "|dk          |\n",
      "|fi          |\n",
      "|lb          |\n",
      "+------------+\n",
      "\n",
      "generated-author-info\n",
      "conferences\n"
     ]
    }
   ],
   "source": [
    "for i, paths_to_csv_file in enumerate(paths_to_csv_files):\n",
    "    print(os.path.splitext(os.path.basename(paths_to_csv_file))[0])\n",
    "    if  os.path.splitext(os.path.basename(paths_to_csv_file))[0] == \"country-info\":\n",
    "        data_frames[i].select(\"countryabbrv\").distinct().show(data_frames[i].count(), False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def check_non_value(df: pyspark.sql.DataFrame):\n",
    "    nan_df = df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "    nan_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0e1dea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name='country-info'\n",
      "root\n",
      " |-- institution: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- countryabbrv: string (nullable = true)\n",
      "\n",
      "+-----------+------+------------+\n",
      "|institution|region|countryabbrv|\n",
      "+-----------+------+------------+\n",
      "|          0|     0|           0|\n",
      "+-----------+------+------------+\n",
      "\n",
      "file_name='generated-author-info'\n",
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- dept: string (nullable = true)\n",
      " |-- area: string (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- adjustedcount: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+-------------+----+\n",
      "|name|dept|area|count|adjustedcount|year|\n",
      "+----+----+----+-----+-------------+----+\n",
      "|   0|   0|   0|    0|            0|   0|\n",
      "+----+----+----+-----+-------------+----+\n",
      "\n",
      "file_name='conferences'\n",
      "root\n",
      " |-- area: string (nullable = true)\n",
      " |-- subarea: string (nullable = true)\n",
      " |-- conference: string (nullable = true)\n",
      "\n",
      "+----+-------+----------+\n",
      "|area|subarea|conference|\n",
      "+----+-------+----------+\n",
      "|   0|      0|         0|\n",
      "+----+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(paths_to_csv_files):\n",
    "    file_name, file_extension = os.path.splitext(os.path.basename(path))\n",
    "    assert file_extension == CSV_SUFFIX\n",
    "    print(f\"{file_name=}\")\n",
    "    curr_df = data_frames[i]\n",
    "    curr_df.printSchema()\n",
    "    check_non_value(curr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}